{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attacks on Neural Networks in a Lightweight Speech Pseudonymization Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daan\\Documents\\Projecten\\ru-automatic-speech-recognition-23-24\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import ASR_2024_anonymization_module_learning.speaker_anonymization as pipeline\n",
    "import ASR_2024_anonymization_module_learning.main as pipeline_optimization\n",
    "\n",
    "import util\n",
    "from backdoored_dataset import BackdooredVCTK\n",
    "from neural_model import NeuralModel\n",
    "from attacks.jingleback import JingleBack\n",
    "from metrics import attack_success_rate, clean_accuracy_drop\n",
    "\n",
    "import torch\n",
    "\n",
    "from torchattacks.attacks.fgsm import FGSM\n",
    "from torchattacks.attacks.pgd import PGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "NVIDIA GeForce GTX 1050\n"
     ]
    }
   ],
   "source": [
    "TARGET_LABEL = 0\n",
    "\n",
    "pipeline_config = pipeline.config.Config(\n",
    "    num_trials=1,\n",
    "    n_speakers=10,\n",
    "    n_samples_per_speaker=10,\n",
    "    gender=None,\n",
    "    min_age=None,\n",
    "    max_age=None,\n",
    "    accent=None,\n",
    "    region=None\n",
    ")\n",
    "\n",
    "util.set_global_seed(3131)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "if str(device) == \"cuda\":\n",
    "    print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attacks\n",
    "### Backdoor Attacks: JingleBack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-03 16:07:32,226 - INFO - Loading data from cache: d:/Datasets/vctk/cache\\cache_10_10_None_None_None_None_None.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n",
      "{'This is a very common type of bow, one showing mainly red and yellow, with little or no green or blue.', 'Two other men, including the taxi driver, were wounded in the attack.', 'It is the whole package.', 'Mark Fisher was a guest of the Northern Ireland Tourist Board.', 'The Norsemen considered the rainbow as a bridge over which the gods passed from earth to their home in the sky.', 'We do not expect any surplus.', 'They are now divorced.', 'He was popular.', 'We will be homeless.', 'The Tory party will last.', 'The group is separate from the Real IRA.', 'Indeed, it is only the beginning.', 'I saw it at a ruck.', 'A spokeswoman for Edinburgh City Council confirmed its support for the company.', 'The procedure is the same in all cases.', 'However, it has to be seen as part of a package.', 'But it might have done.', 'As it was a double, it was pretty expensive.', 'It is not for any other purpose.', 'Here, again, they were denied a voice.', 'A web site is planned for November.', 'We remain confident that Danny is still alive.', 'This should come as no surprise.', 'Others have tried to explain the phenomenon physically.', 'Wallace was a prisoner of war.', \"I'm just asking them to improve their disciplines.\", 'I am sorry, but I forgot.', 'Today she has been released.', 'If it does it means he has failed.', 'Our numbers are small.', 'One thing is sure.', 'Mexico City was a wonderful experience.', 'The eye was badly closed on Sunday.', 'I had decided to quit the show.', 'This year, this month, will be special for Torrance.', 'Nato has left them with no other option.', 'If the red of the second bow falls upon the green of the first, the result is to give a bow with an abnormally wide yellow band, since red and green light when mixed form yellow.', 'To the Hebrews it was a token that there would be no more universal floods.', 'We never played at all.', 'Sadly, the revival could not be sustained.', 'The decision was announced at its annual conference in Dunfermline.', 'Diversions were put in place.', 'It should be equal.', 'So it was at Easter Road.', 'I have played really well all year.', 'The Home Office would not release any further details about the group.', 'It would be a last resort.', 'At the same time it is a satire.', 'We also need a small plastic snake and a big toy frog for the kids.', 'That was a bonus, but it was not the main objective.', 'He liked to give the impression of being a hard man.', \"We've made a couple of albums.\", 'He takes the job.', 'Hartley should know.', 'They make a selective perception process.', 'We have to work together.', 'Last night, he pledged to clear his name.', 'Two years of building a business will go up in smoke.', 'Gordon Brown did not inherit a mess.', 'It is simply not true.', 'The pair are no strangers to smashing records.', 'We were very much a happy family.', \"He did his best, but it wasn't good enough.\", \"I can't even get into the A team.\", 'That group reported just before Christmas.', 'A Grampian Police spokesman said.', 'Kids are terrible.', 'It is a sensitive issue.', 'We are in the hat.', \"It's very odd.\", 'It is a hard act to follow, the Winning act.', 'Further details are expected later.', 'They made clear that they are not interested in Government assistance.', 'They were not at the property yesterday.', 'I did not think about the Ryder Cup.', 'Of course, it does not have to be this way.', 'I still hope to go.', \"I'm sure everyone will be delighted for them.\", 'I would like to see the figures  for the second quarter.', 'Florida is the pivotal state in the nation.', 'Who would be right?', 'I never had a childhood.', 'Now, though, he believes that the new formation has helped his form.', 'It is a private matter between the firm and our staff.', \"It's going to be very closely watched.\", \"I'm so worried about the roads.\", 'From day one, we were a family.', 'I needed to get away.', 'The first time it was rejected.', 'I want to go home.', 'The funding is now there.', 'We agreed to disagree.', 'Now, suddenly, we have this new landscape.', 'I decided to tell a bit of the story about myself.', 'Nonetheless, the overall picture is healthy.', 'Surely, the Scottish Parliament is entitled to take a view on that.', 'It was a very strong metaphor.', 'However, on the other hand, in principle it is plainly wrong.', 'So what is the campaign about?', 'Had this been common practice?'}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m jingleback_attack \u001b[38;5;241m=\u001b[39m JingleBack(source_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, target_label\u001b[38;5;241m=\u001b[39mTARGET_LABEL)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# model = NeuralModel(attack=jingleback_attack, device=device)\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m backdoored_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mBackdooredVCTK\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjingleback_attack\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpipeline_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpipeline_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Daan\\Documents\\Projecten\\ru-automatic-speech-recognition-23-24\\code\\backdoored_dataset.py:21\u001b[0m, in \u001b[0;36mBackdooredVCTK.__init__\u001b[1;34m(self, backdoor, epsilon, train, pipeline_config)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# self.clean_dataset = datasets.load.load_dataset(\"vctk\", split=\"train\" if train else \"test\", cache_dir=\"d:/Datasets/vctk/cache\")\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclean_dataset \u001b[38;5;241m=\u001b[39m CachedVCTK(pipeline_config)\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclean_dataloader \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoader\u001b[49m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclean_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackdoor \u001b[38;5;241m=\u001b[39m backdoor\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackdoored_dataset \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\Daan\\Documents\\Projecten\\ru-automatic-speech-recognition-23-24\\code\\backdoored_dataset.py:21\u001b[0m, in \u001b[0;36mBackdooredVCTK.__init__\u001b[1;34m(self, backdoor, epsilon, train, pipeline_config)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# self.clean_dataset = datasets.load.load_dataset(\"vctk\", split=\"train\" if train else \"test\", cache_dir=\"d:/Datasets/vctk/cache\")\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclean_dataset \u001b[38;5;241m=\u001b[39m CachedVCTK(pipeline_config)\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclean_dataloader \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoader\u001b[49m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclean_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackdoor \u001b[38;5;241m=\u001b[39m backdoor\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackdoored_dataset \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Daan\\Documents\\Projecten\\ru-automatic-speech-recognition-23-24\\env\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[1;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Daan\\Documents\\Projecten\\ru-automatic-speech-recognition-23-24\\env\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[0;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[1;32m-> 2106\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[0;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "jingleback_attack = JingleBack(source_label=None, target_label=TARGET_LABEL)\n",
    "# model = NeuralModel(attack=jingleback_attack, device=device)\n",
    "\n",
    "backdoored_dataset = BackdooredVCTK(jingleback_attack, epsilon=0.05, train=True, pipeline_config=pipeline_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evasion Attacks: FGSM & PGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgsm = FGSM(model.neural_network, eps=8/255)\n",
    "fgsm.set_mode_targeted_by_label() #NOTE: This means that, when attacking the model, you should pass the target label manually/yourself. So fgsm(audio, target_label)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgsm = PGD(model.neural_network, eps=8/255, alpha=2/255, steps=10, random_start=True)\n",
    "fgsm.set_mode_targeted_by_label() #NOTE: This means that, when attacking the model, you should pass the target label manually/yourself. So fgsm(audio, target_label)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [pipeline_config]\n",
    "pipeline_optimization.run_optimization(pipeline_config)\n",
    "\n",
    "asv_model = pipeline.spi.SpeakerIdentificationModel() # ASV model\n",
    "asv_model.finetune_model() # Method for finetuning ASV model during initialisation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
