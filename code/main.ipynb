{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attacks on Neural Networks in a Lightweight Speech Pseudonymization Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ASR_2024_anonymization_module_learning.speaker_anonymization as pipeline\n",
    "import ASR_2024_anonymization_module_learning.speaker_anonymization.optimize as pipeline_optimize\n",
    "\n",
    "import util\n",
    "from backdoored_dataset import BackdooredVCTK, CachedVCTK\n",
    "from attacks.jingleback import JingleBack\n",
    "from attacks.fgsm import FGSM\n",
    "from attacks.pgd import PGD\n",
    "from metrics import attack_success_rate, clean_accuracy_drop\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config_train = pipeline.config.Config(\n",
    "    num_trials=5,\n",
    "    n_speakers=10,\n",
    "    n_samples_per_speaker=10,\n",
    "    gender=None,\n",
    "    min_age=None,\n",
    "    max_age=None,\n",
    "    accent=None,\n",
    "    region=None\n",
    ")\n",
    "\n",
    "pipeline_config_test = pipeline.config.Config(\n",
    "    num_trials=1,\n",
    "    n_speakers=10,\n",
    "    n_samples_per_speaker=100,\n",
    "    gender=None,\n",
    "    min_age=None,\n",
    "    max_age=None,\n",
    "    accent=None,\n",
    "    region=None\n",
    ")\n",
    "\n",
    "os.makedirs(os.path.join(pipeline_config_train.BACKDOORED_FOLDER, \"train\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(pipeline_config_train.BACKDOORED_FOLDER, \"test\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(pipeline_config_train.PERTURBED_FOLDER, \"fgsm\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(pipeline_config_train.PERTURBED_FOLDER, \"pgd\"), exist_ok=True)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "util.set_global_seed(3131)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "if str(device) == \"cuda\":\n",
    "    print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Clean and Backdoored Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_test_set = CachedVCTK(pipeline_config_test)\n",
    "\n",
    "\n",
    "TARGET_SPEAKER_ID = 0\n",
    "jingleback_attack = JingleBack(source_label=None, target_label=TARGET_SPEAKER_ID)\n",
    "\n",
    "backdoored_test_set = BackdooredVCTK(jingleback_attack, poisoning_rate=1.0, train=False, pipeline_config=pipeline_config_test)\n",
    "backdoored_test_loader = DataLoader(backdoored_test_set, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing the Clean Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_asr_processor, clean_asr_model, clean_asv_model, clean_wer, clean_asv_acc, _ = pipeline_optimize.optimize_audio_effects(pipeline_config_train, stop_after_model_evaluation=True)\n",
    "clean_asv_asr, _ = attack_success_rate(clean_asv_model, backdoored_test_loader, target_label=TARGET_SPEAKER_ID, device=device)\n",
    "\n",
    "print(\"WER:\", clean_wer)\n",
    "print(\"ASV Acc:\", clean_asv_acc)\n",
    "print(\"ASV ASR:\", clean_asv_asr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing Backdoored Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poisoning_rates = [0.05, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "\n",
    "asr_word_error_rates = []\n",
    "asr_word_error_rate_increases = []\n",
    "asv_accuracies = []\n",
    "asv_attack_success_rates = []\n",
    "asv_clean_accuracy_drops = []\n",
    "\n",
    "for poisoning_rate in poisoning_rates:\n",
    "    backdoored_train_set = BackdooredVCTK(jingleback_attack, poisoning_rate=poisoning_rate, train=True, pipeline_config=pipeline_config_train)\n",
    "    backdoored_train_loader = DataLoader(backdoored_train_set, batch_size=1, shuffle=True)\n",
    "    \n",
    "    asr_processor, asr_model, asv_model, mean_wer, mean_asv_acc, _ = pipeline_optimize.optimize_audio_effects(pipeline_config_train, backdoored_vctk=backdoored_train_set, stop_after_model_evaluation=True)\n",
    "    \n",
    "    weri = mean_wer - clean_wer\n",
    "    asr, _ = attack_success_rate(asv_model, backdoored_test_loader, target_label=TARGET_SPEAKER_ID, device=device)\n",
    "    cad = clean_accuracy_drop(clean_asv_model, asv_model, clean_test_set)\n",
    "    \n",
    "    asr_word_error_rates.append(mean_wer)\n",
    "    asr_word_error_rate_increases.append(weri)\n",
    "    asv_accuracies.append(mean_asv_acc)\n",
    "    asv_attack_success_rates.append(asr)\n",
    "    asv_clean_accuracy_drops.append(cad)\n",
    "    \n",
    "    print(\"Poisoning Rate:\", poisoning_rate)\n",
    "    print(\"    ASR Word Error Rate:\", mean_wer)\n",
    "    print(\"    ASR Word Error Rate Increase:\", weri)\n",
    "    print(\"    ASV Accuracy:\", mean_asv_acc)\n",
    "    print(\"    ASV Attack Success Rate:\", asr)\n",
    "    print(\"    ASV Clean Accuracy Drop:\", cad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Backdoor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizations = []\n",
    "visualizations.append([0, \"WER\", clean_wer])\n",
    "visualizations.append([0, \"Acc\", clean_asv_acc])\n",
    "visualizations.append([0, \"ASR\", clean_asv_asr])\n",
    "\n",
    "for i in range(len(poisoning_rates)):\n",
    "    visualizations.append([poisoning_rates[i], \"WER\", asr_word_error_rates[i]])\n",
    "    visualizations.append([poisoning_rates[i], \"WERI\", asr_word_error_rate_increases[i]])\n",
    "    visualizations.append([poisoning_rates[i], \"Acc\", asv_accuracies[i]])\n",
    "    visualizations.append([poisoning_rates[i], \"ASR\", asv_attack_success_rates[i]])\n",
    "    visualizations.append([poisoning_rates[i], \"CAD\", asv_clean_accuracy_drops[i]])\n",
    "    \n",
    "visualizations_df = pd.DataFrame(visualizations, columns=[\"Poisoning Rate\", \"Metric\", \"Value\"])\n",
    "display(visualizations_df)\n",
    "\n",
    "sns.set_theme(rc={'figure.figsize':(10, 5)})\n",
    "sns.pointplot(data=visualizations_df, x=\"Poisoning Rate\", y=\"Value\", hue=\"Metric\", hue_order=[\"WER\", \"WERI\", \"Acc\", \"CAD\", \"ASR\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing Evasion Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_utterances, speaker_ids, transcriptions, _, _ = clean_test_set[:]\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgsm = FGSM(clean_asv_model, eps=8/255)\n",
    "fgsm.set_mode_targeted_by_label(quiet=True)\n",
    "\n",
    "fgsm_utterances = []\n",
    "for index, utterance in enumerate(clean_utterances):\n",
    "    fgsm_utterance = fgsm(utterance, TARGET_SPEAKER_ID)\n",
    "    fgsm_utterances.append(fgsm_utterance)\n",
    "    \n",
    "    utterance_file_name = f\"index{index}_speaker{speaker_ids[index]}_fgsm_target{TARGET_SPEAKER_ID}.wav\"\n",
    "    utterance_file_path = \"d:/Datasets/vctk/perturbed_audio/fgsm/\" + utterance_file_name\n",
    "    torchaudio.save(uri=utterance_file_path, src=fgsm_utterance.cpu(), sample_rate=16000)\n",
    "\n",
    "predicted_transcriptions, predicted_speakers, fgsm_wer, fgsm_asv_acc, _ = pipeline_optimize.evaluate_asr_and_asv(\n",
    "    audio_data=[(fgsm_utterance.squeeze().to(device), None) for fgsm_utterance in fgsm_utterances],\n",
    "    transcriptions=transcriptions,\n",
    "    speakers=speaker_ids,\n",
    "    asr_processor=clean_asr_processor,\n",
    "    asr_model=clean_asr_model,\n",
    "    asv_model=clean_asv_model,\n",
    "    CONFIG=pipeline_config_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgd = PGD(clean_asv_model, eps=8/255, alpha=2/255, steps=10, random_start=True)\n",
    "pgd.set_mode_targeted_by_label(quiet=True)\n",
    "\n",
    "pgd_utterances = []\n",
    "for index, utterance in enumerate(clean_utterances):\n",
    "    pgd_utterance = pgd(utterance, TARGET_SPEAKER_ID)\n",
    "    pgd_utterances.append(pgd_utterance)\n",
    "    \n",
    "    utterance_file_name = f\"index{index}_speaker{speaker_ids[index]}_pgd_target{TARGET_SPEAKER_ID}.wav\"\n",
    "    utterance_file_path = \"d:/Datasets/vctk/perturbed_audio/pgd/\" + utterance_file_name\n",
    "    torchaudio.save(uri=utterance_file_path, src=pgd_utterance.cpu(), sample_rate=16000)\n",
    "\n",
    "predicted_transcriptions, predicted_speakers, pgd_wer, pgd_asv_acc, _ = pipeline_optimize.evaluate_asr_and_asv(\n",
    "    audio_data=[(pgd_utterance.squeeze().to(device), None) for pgd_utterance in pgd_utterances],\n",
    "    transcriptions=transcriptions,\n",
    "    speakers=speaker_ids,\n",
    "    asr_processor=clean_asr_processor,\n",
    "    asr_model=clean_asr_model,\n",
    "    asv_model=clean_asv_model,\n",
    "    CONFIG=pipeline_config_test\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
